{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "minor",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Atomnp/realtime_text_similarity_backend/blob/main/minor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeRbR-2NAvAS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer,\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix, lil_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ],
   "metadata": {
    "id": "wysvPmYtEjY0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cdd3ac3e-42f8-431a-f9ba-1a91dad73648"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# mounting your google drive to colab\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/gdrive\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xloBLoD9FfKw",
    "outputId": "95851902-eae9-4c25-be14-d72590a359ae"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Make shortcut of [this](https://drive.google.com/drive/folders/1BGr0cWKiJwT_jNg9nRNAhWgy0mYPgw_K?usp=sharing) folder in your gdrive**"
   ],
   "metadata": {
    "id": "cJnXuBlZG23A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"Callback to print loss after each epoch.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print(\"Loss after epoch {}: {}\".format(self.epoch, loss))\n",
    "        else:\n",
    "            print(\n",
    "                \"Loss after epoch {}: {}\".format(\n",
    "                    self.epoch, loss - self.loss_previous_step\n",
    "                )\n",
    "            )\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ],
   "metadata": {
    "id": "2sNEI7X9M3di"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# load dataset\n",
    "dataset = r\"/gdrive/MyDrive/minor_project_files/questions.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset, keep_default_na=False, na_values=[\"_\"])\n",
    "questions = df.loc[:, \"question1\"].to_list()"
   ],
   "metadata": {
    "id": "42wJ0pffSiRN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zNf4z_XgJx15",
    "outputId": "ba08b696-6f72-4933-95e1-7c79898a749c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-788870fb-5e82-46a9-8ffe-c5098d54c5a9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-788870fb-5e82-46a9-8ffe-c5098d54c5a9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-788870fb-5e82-46a9-8ffe-c5098d54c5a9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-788870fb-5e82-46a9-8ffe-c5098d54c5a9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
       "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
       "4   4     9  ...            Which fish would survive in salt water?            0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# train and save model\n",
    "sentences = (word_tokenize(sentence) for sentence in questions)\n",
    "\n",
    "# model = Word2Vec(sentences=list(sentences), size=100, window=5, min_count=1, workers=4, compute_loss=True, iter=6, callbacks=[callback()])\n",
    "# model.save(\"/gdrive/MyDrive/minor_project_files/word2vec.model\")"
   ],
   "metadata": {
    "id": "ysCGVpAeOUbE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def word2vec(word):\n",
    "    model = Word2Vec.load(\"/gdrive/MyDrive/minor_project_files/word2vec.model\")\n",
    "    return model.wv[word]"
   ],
   "metadata": {
    "id": "6N1UnBrUORUe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# word_vec= word2vec('king')\n",
    "# print(word_vec)\n",
    "model = Word2Vec.load(\"/gdrive/MyDrive/minor_project_files/word2vec.model\")\n",
    "# print(model.wv.most_similar(positive=['king'], negative=[], topn=50))"
   ],
   "metadata": {
    "id": "e5EFHZyWOdsV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# not used\n",
    "idf_scores = {}\n",
    "key_words = []\n",
    "tfidf_matrix = []"
   ],
   "metadata": {
    "id": "ucJkyOv54geZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# not used\n",
    "def extract_key_words(corpus: List[List[str]], num_of_words=3):\n",
    "    global idf_scores\n",
    "    global key_words\n",
    "    global tfidf_matrix\n",
    "\n",
    "    def identity_tokenizer(text):\n",
    "        return text\n",
    "\n",
    "    # vect = TfidfVectorizer(max_df=0.8, max_features=200000, min_df=0.2, stop_words=nltk.corpus.stopwords.words('english'), use_idf=True, tokenizer=identity_tokenizer,lowercase=False)\n",
    "    vect = TfidfVectorizer(\n",
    "        stop_words=nltk.corpus.stopwords.words(\"english\"),\n",
    "        use_idf=True,\n",
    "        tokenizer=identity_tokenizer,\n",
    "        lowercase=True,\n",
    "    )\n",
    "    tfidf_matrix = vect.fit_transform(corpus)\n",
    "\n",
    "    print(vect.idf_)\n",
    "\n",
    "    idf_scores = dict(zip(vect.get_feature_names(), vect.idf_))\n",
    "\n",
    "    test = vect.fit([\"this is some random text i got from somewhere\".split()])\n",
    "    print(test)\n",
    "    print(vect.get_feature_names())\n",
    "\n",
    "    # df = pd.DataFrame(tfidf_matrix.toarray(), columns=vect.get_feature_names())\n",
    "    # key_words = df.apply(lambda x:x.nlargest(num_of_words).index.values,axis=1)\n",
    "\n",
    "    # return df.apply(lambda x:x.nlargest(num_of_words).index.values,axis=1).to_list()"
   ],
   "metadata": {
    "id": "cE3BLw6lA4WD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# extract_key_words(itertools.islice(sentences, 50000))\n",
    "# extract_key_words(sentences)"
   ],
   "metadata": {
    "id": "bJ2FZLKchbN5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "^^ First train the model on the entire dataset"
   ],
   "metadata": {
    "id": "Y_gDCmUi3T32"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# vect = TfidfVectorizer(max_df=0.8, max_features=200000, min_df=0.2, stop_words=nltk.corpus.stopwords.words('english'), use_idf=True, tokenizer=identity_tokenizer,lowercase=False)\n",
    "vect = TfidfVectorizer(\n",
    "    stop_words=nltk.corpus.stopwords.words(\"english\"),\n",
    "    use_idf=True,\n",
    "    tokenizer=identity_tokenizer,\n",
    "    lowercase=False,\n",
    ")\n",
    "# copy the iterator so that the cell can be rerun (otherwise the iterator will be at the end)\n",
    "it_copy, sentences = itertools.tee(sentences)\n",
    "tfidf_matrix = vect.fit_transform(it_copy)\n",
    "fv = vect.get_feature_names()\n",
    "\n",
    "# print(vect.idf_, len(vect.idf_))"
   ],
   "metadata": {
    "id": "qK8-4oYe2Xb_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "54e41065-e3cd-4a2b-9828-2239c77f9708"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 6.03 s, sys: 142 ms, total: 6.17 s\n",
      "Wall time: 6.52 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# implementation to find sentence embeddings (alternative 1) : lil_matrix! 2m4s!!\n",
    "it_copy, sentences = itertools.tee(sentences)\n",
    "sem = []\n",
    "# cx = coo_matrix(tfidf_matrix)\n",
    "cx = lil_matrix(tfidf_matrix)"
   ],
   "metadata": {
    "id": "HXMKv8ZE49dt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sem = []\n",
    "to = cx.get_shape()[0]\n",
    "for i in range(to):\n",
    "    rx = cx.getrow(i).tocoo()\n",
    "\n",
    "    sorted_by_tfidf = sorted(\n",
    "        [(fv[j], v) for k, j, v in zip(rx.row, rx.col, rx.data)],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "    arrlist = np.array(list(map(lambda x: model.wv[x[0]], sorted_by_tfidf[:5])))\n",
    "    sem.append(np.mean(arrlist, axis=0))\n",
    "\n",
    "sem = np.asarray(sem)\n",
    "np.save(\"/gdrive/MyDrive/minor_project_files/sentence_embeddings2.npy\", sem)"
   ],
   "metadata": {
    "id": "Hlr9BemrwnRQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# implementation to find sentence embeddings (alternative 2) faster: 13 minutes\n",
    "\n",
    "# it_copy, sentences = itertools.tee(sentences)\n",
    "# sem = []\n",
    "# for sentence in itertools.islice(it_copy, 1000):\n",
    "#     # print(sentence)\n",
    "#     matrix = vect.transform([sentence])\n",
    "#     # iterating over the sparse matrix representatin using COOrdinate matrix\n",
    "#     cx = coo_matrix(matrix)\n",
    "\n",
    "#     sorted_by_tfidf = sorted([(fv[j],v) for i,j,v in zip(cx.row, cx.col, cx.data)], key=lambda x: x[1], reverse=True)\n",
    "#     arrlist = np.array( list(map(lambda x: model.wv[x[0]], sorted_by_tfidf[:5])  ))\n",
    "#     sem.append(np.mean(arrlist, axis=0))\n",
    "# sem = np.asarray(sem)\n",
    "# np.save('/gdrive/MyDrive/minor_project_files/sentence_embeddings.npy', sem)"
   ],
   "metadata": {
    "id": "ZmBWGMjNd-z2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# save idf_scores (but we dont need to do this it seems)\n",
    "# idf_scores = dict(zip(vect.get_feature_names(), vect.idf_))"
   ],
   "metadata": {
    "id": "cjjlEQvE2iMI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# sample block on how to get the tfidf score of new question\n",
    "# get similar words from question string\n",
    "def get_similar_words(question: str):\n",
    "    to_transform = [question.split()]\n",
    "    matrix = vect.transform(to_transform)\n",
    "    print(matrix)\n",
    "\n",
    "    # iterating over the sparse matrix representatin using COOrdinate matrix\n",
    "    cx = coo_matrix(matrix)\n",
    "    sorted_by_tfidf = sorted(\n",
    "        [(fv[j], v) for i, j, v in zip(cx.row, cx.col, cx.data)],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "    print(sorted_by_tfidf)\n",
    "\n",
    "    most_similar = []\n",
    "    for i in range(len(sorted_by_tfidf)):\n",
    "        element = sorted_by_tfidf[i]\n",
    "        top3similar = model.wv.most_similar(positive=[element[0]], negative=[], topn=3)\n",
    "        most_similar += [(k[0], k[1] * element[1]) for k in top3similar]\n",
    "\n",
    "    most_similar = sorted(most_similar, key=lambda x: x[1], reverse=True)\n",
    "    print(most_similar)\n",
    "    return most_similar"
   ],
   "metadata": {
    "id": "cVWbdWk237rz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(get_similar_words(\"what is the best way to invest in India stock market?\"))"
   ],
   "metadata": {
    "id": "0Cs9GxSPGI9V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "^^ "
   ],
   "metadata": {
    "id": "mfx71jAF2i5J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def similarity_two_key_words(v1, v2):\n",
    "    # s_k=extract_key_words([corpus_s],5)[0]\n",
    "    # print(v1,s_k)\n",
    "    ev1 = [model.wv[word] for word in v1]\n",
    "    ev2 = [model.wv[word] for word in v2]\n",
    "    sim = cosine_similarity(ev1, ev2)\n",
    "    return np.prod(np.amax(sim, axis=1))"
   ],
   "metadata": {
    "id": "ZvtWur4xeir9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_similar(sentence: str, n: int = 5):\n",
    "    # print(word_tokenize(sentence))\n",
    "    # key_words=extract_key_words([word_tokenize(sentence)],5)\n",
    "    # print(sentences[:1000])\n",
    "\n",
    "    # corpus=[word_tokenize(sentence)]+sentences[:1000]\n",
    "    # key_words=extract_key_words(corpus,5)\n",
    "\n",
    "    score = [similarity_two_key_words(key_words[0], question) for question in key_words]\n",
    "    similarity = create_dict(score, [sentence] + questions[:1000])\n",
    "\n",
    "    # sort based on score and return n similar items\n",
    "    return dict(\n",
    "        itertools.islice(\n",
    "            dict(sorted(similarity.items(), key=lambda x: x[0], reverse=True)).items(),\n",
    "            n,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dict(score, questions):\n",
    "    return dict(zip(score, questions))"
   ],
   "metadata": {
    "id": "0LdqWaCmeR8a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "a = get_similar(\"who is albert einstein how did he becaome so genius?\")\n",
    "print(a)"
   ],
   "metadata": {
    "id": "CXGtOzOLcG8t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running Flask on collab"
   ],
   "metadata": {
    "id": "CfEnbd3JTV-4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null\n",
    "!echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list\n",
    "!sudo apt update && sudo apt install ngrok\n",
    "!pip install flask_ngrok flask-bootstrap\n",
    "!pip install flask_restful flask_cors\n",
    "!cat /gdrive/MyDrive/minor_project_files/ngrok_token | xargs ngrok authtoken"
   ],
   "metadata": {
    "id": "moNKtS4sXFgR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "stdout = sys.stdout\n",
    "stderr = sys.stderr"
   ],
   "metadata": {
    "id": "4L4DjSwU-Avm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"test\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGs-FuZu_O7z",
    "outputId": "fbe3af98-d1fc-48a9-84c5-0dd8d3d25fb6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from flask_restful import Resource, Api\n",
    "import os, logging, sys\n",
    "from flask_cors import CORS, cross_origin\n",
    "\n",
    "# sys.stdout = open(\"/gdrive/MyDrive/minor_project_files/test.txt\", \"w\", buffering=1)\n",
    "# sys.stderr = open(\"/gdrive/MyDrive/minor_project_files/test.txt\", \"a\", buffering=1)\n",
    "\n",
    "app = Flask(__name__)\n",
    "cors = CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "# cors = CORS(app)\n",
    "# app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "api = Api(app)\n",
    "\n",
    "run_with_ngrok(app)\n",
    "\n",
    "\n",
    "class Similarity(Resource):\n",
    "    # get endpoint to check server is up\n",
    "    def get(self):\n",
    "        return jsonify({\"hello\": \"Server Online!\"})\n",
    "\n",
    "    def post(self):\n",
    "        json_data = request.get_json(force=True)\n",
    "        qn = json_data[\"question\"]\n",
    "        # similarity = get_similar(qn)\n",
    "        # return list of questions\n",
    "        x = [\"question 1\", \"question 2\"]\n",
    "        return x\n",
    "\n",
    "\n",
    "api.add_resource(Similarity, \"/\")\n",
    "app.run()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qp3oi91wTVVI",
    "outputId": "ea23714d-7849-44f4-9e97-cf7dff2d648e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Running on http://a520-35-227-155-192.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "127.0.0.1 - - [02/Feb/2022 15:20:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2022 15:20:49] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sys.stdout = stdout\n",
    "sys.stderr = stderr"
   ],
   "metadata": {
    "id": "gRPs5eKO7nkt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "P0Eps0Ou78w9"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
